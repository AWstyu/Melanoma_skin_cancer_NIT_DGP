{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134dc54-eb1f-427a-b326-64ee78292070",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas matplotlib pillow opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9783d5a-de1f-4d7c-b8a1-a7df10f59919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e1394-da67-4cfc-82c2-df78942dcc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3198c-38a2-47f1-8484-11478f90fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019e3ea-5cdf-437b-a281-3e1b85b56c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e732d-0578-4e58-9f9e-4ac428e69f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign'\n",
    "images=os.listdir(path)\n",
    "len(images)\n",
    "\n",
    "path='C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\malignant'\n",
    "images=os.listdir(path)\n",
    "len(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74874ba-404c-4c58-ba7b-6648caa4f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006f801-14fe-4a80-97ee-98e646ae3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_benign='C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign'\n",
    "path_malignant='C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\malignant'\n",
    "\n",
    "\n",
    "def load_images_with_labels(path,label):\n",
    "    images=os.listdir(path)\n",
    "    labeled_images=[]\n",
    "    for img in images:\n",
    "        img_path=os.path.join(path,img)\n",
    "        img_arr=cv2.imread(img_path)\n",
    "        if img_arr is not None:\n",
    "            labeled_images.append((img_arr,label))\n",
    "    return labeled_images       \n",
    "\n",
    "benign_images=load_images_with_labels(path_benign,0)\n",
    "malignant_images=load_images_with_labels(path_malignant,1)\n",
    "\n",
    "data_images=benign_images+malignant_images\n",
    "\n",
    "print(len(data_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ccf18-3520-429f-9d36-a3f48ffad2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "path_benign='C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign'\n",
    "path_malignant='C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\malignant'\n",
    "\n",
    "\n",
    "def load_images_with_labels(path,label,num_samples):\n",
    "    images=os.listdir(path)\n",
    "    if num_samples>len(images):\n",
    "        num_samples=len(images)\n",
    "    selected_images=random.sample(images,num_samples)    \n",
    "    labeled_images=[]\n",
    "    for img in selected_images:\n",
    "        img_path=os.path.join(path,img)\n",
    "        img_arr=cv2.imread(img_path)\n",
    "        if img_arr is not None:\n",
    "            labeled_images.append((img,label))\n",
    "    return labeled_images       \n",
    "\n",
    "benign_images=load_images_with_labels(path_benign,0,1000)\n",
    "malignant_images=load_images_with_labels(path_malignant,1,1000)\n",
    "\n",
    "data_images_mod=benign_images+malignant_images\n",
    "\n",
    "print(len(data_images_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48b4d8-ebe2-4394-8022-316c1341e506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data_images_mod)\n",
    "\n",
    "for img,label in data_images_mod:\n",
    "    print(label,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29a095-0fdd-4965-a3f7-b041d82e711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f06698-419d-466f-a7f5-f682fab407c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\ML_PROJECTS')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c689a4c-199a-4791-bdba-544b1da9c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'image_name': [img_name for img_name,_ in data_images_mod],\n",
    "    'status': [label for _, label in data_images_mod]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "excel_path = 'melanoma_org_1.xlsx'\n",
    "df.to_excel(excel_path, index=False)\n",
    "\n",
    "print(f\"Excel file saved to {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff96d8c-cb3b-471a-bc15-a56ef09d10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2830a5-8504-436c-ab77-ec8e6f12977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\ML_PROJECTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9adc3-153d-477d-82cd-98fee9358800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "memory_info = psutil.virtual_memory()\n",
    "print(f\"Total memory: {memory_info.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available memory: {memory_info.available / (1024 ** 3):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca130d5-b5e5-435e-bda2-8dc10455265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a83eb5-d34f-468f-895b-a72288d4e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "df = pd.read_excel('melanoma_org_1.xlsx')\n",
    "\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "   \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "def process_batch(batch_df):\n",
    " \n",
    "    features = []\n",
    "    for index, row in batch_df.iterrows():\n",
    "        img_name = row['image_name']\n",
    "        status = row['status']\n",
    "        if status==0:\n",
    "          img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign', img_name)\n",
    "        else:\n",
    "          img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\malignant', img_name)\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "        try:\n",
    "            img = load_and_preprocess_image(img_path)\n",
    "            feature_vector = model.predict(img)\n",
    "            feature_vector = feature_vector.flatten()\n",
    "            features.append([img_name, feature_vector])\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File not found: {img_path}\")\n",
    "            continue\n",
    "    return features\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "all_features = []\n",
    "\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[i:i+batch_size]\n",
    "    batch_features = process_batch(batch_df)\n",
    "    all_features.extend(batch_features)\n",
    " \n",
    "    intermediate_df = pd.DataFrame(batch_features, columns=['Image_name', 'Feature_vector'])\n",
    "    intermediate_df.to_pickle(f'vgg16_features_batch_{i//batch_size}.pkl')\n",
    "    # Clear memory\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddcb23-f352-4ca1-a09c-afdde569fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "df = pd.read_excel('melanoma_org_1.xlsx')\n",
    "\n",
    "\n",
    "base_model = VGG19(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "   \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "def process_batch(batch_df):\n",
    "   \n",
    "    features = []\n",
    "    for index, row in batch_df.iterrows():\n",
    "        img_name = row['image_name']\n",
    "        status = row['status']\n",
    "        if status==0:\n",
    "          img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign', img_name)\n",
    "        else:\n",
    "          img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\malignant', img_name)\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "        try:\n",
    "            img = load_and_preprocess_image(img_path)\n",
    "            feature_vector = model.predict(img)\n",
    "            feature_vector = feature_vector.flatten()\n",
    "            features.append([img_name, feature_vector])\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File not found: {img_path}\")\n",
    "            continue\n",
    "    return features\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "all_features = []\n",
    "\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[i:i+batch_size]\n",
    "    batch_features = process_batch(batch_df)\n",
    "    all_features.extend(batch_features)\n",
    " \n",
    "    intermediate_df = pd.DataFrame(batch_features, columns=['Image_name', 'Feature_vector'])\n",
    "    intermediate_df.to_pickle(f'vgg19_features_batch_{i//batch_size}.pkl')\n",
    "   \n",
    "    gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f7454-2d9f-4f4c-b6d1-e92ce553d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\ML_PROJECTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea8c97-196c-49dd-a8cb-f7b5edbe169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "data_list=[]\n",
    "\n",
    "for i in range(10):\n",
    "    filename=f\"vgg16_features_batch_{i}.pkl\"\n",
    "    with open(filename,'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        data_list.append(data)\n",
    "\n",
    "concatenated_data = np.concatenate(data_list, axis=0)\n",
    "\n",
    "with open('vgg16_features_concatenated.pkl', 'wb') as f:\n",
    "    pickle.dump(concatenated_data, f)\n",
    "\n",
    "print(\"Concatenation complete and saved to 'vgg16_features_concatenated.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4e6a4-748d-4291-bcbe-6f02f9c6d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "for i in range(10):\n",
    "    filename=f\"vgg19_features_batch_{i}.pkl\"\n",
    "    with open(filename,'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        data_list.append(data)\n",
    "\n",
    "\n",
    "concatenated_data=np.concatenate(data_list,axis=0)\n",
    "\n",
    "with open('vgg19_features_concatenated.pkl','wb') as f:\n",
    "    pickle.dump(concatenated_data,f)\n",
    "\n",
    "print(\"Concatenation complete and saved to 'vgg19_features_concatenated.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ccfda-39b7-46eb-bc01-63b2b0c88b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "df = pd.read_excel('melanoma_org_1.xlsx')\n",
    "\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "def process_batch(batch_df):\n",
    "    \n",
    "    features = []\n",
    "    for index, row in batch_df.iterrows():\n",
    "        img_name = row['image_name']\n",
    "        status = row['status']\n",
    "        if status == 0:\n",
    "            img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign', img_name)\n",
    "        else:\n",
    "            img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\malignant', img_name)\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "        try:\n",
    "            img = load_and_preprocess_image(img_path)\n",
    "            feature_vector = model.predict(img)\n",
    "            feature_vector = feature_vector.flatten()\n",
    "            features.append([img_name, feature_vector])\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File not found: {img_path}\")\n",
    "            continue\n",
    "    return features\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "all_features = []\n",
    "\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[i:i+batch_size]\n",
    "    batch_features = process_batch(batch_df)\n",
    "    all_features.extend(batch_features)\n",
    "  \n",
    "    intermediate_df = pd.DataFrame(batch_features, columns=['Image_name', 'Feature_vector'])\n",
    "    intermediate_df.to_pickle(f'densenet_features_batch_{i//batch_size}.pkl')\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "print(\"Feature extraction complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7762e632-9ec2-4ff4-9c72-be07db17fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "for i in range(10):\n",
    "    filename=f\"densenet_features_batch_{i}.pkl\"\n",
    "    with open(filename,'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        data_list.append(data)\n",
    "\n",
    "\n",
    "concatenated_data=np.concatenate(data_list,axis=0)\n",
    "\n",
    "with open('densenet_features_concatenated.pkl','wb') as f:\n",
    "    pickle.dump(concatenated_data,f)\n",
    "\n",
    "print(\"Concatenation complete and saved to 'densenet_features_concatenated.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26aa36-bcc5-475d-a8ee-0a9da7042ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe30f9-788f-48fa-98f8-96e7ad9d2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\ML_PROJECTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce51dc-b6c3-4e52-bc6e-c765dbbb56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f1=\"vgg16_features_concatenated.pkl\"\n",
    "f2=\"vgg19_features_concatenated.pkl\"\n",
    "f3=\"densenet_features_concatenated.pkl\"\n",
    "\n",
    "with open(f1,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "for img,f_v in data:\n",
    "    print(f'{img},{f_v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f9ec1-6858-4f5e-b79b-18a38db73984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_shape=12288\n",
    "\n",
    "flattened_vector=np.random.rand(input_shape)\n",
    "\n",
    "\n",
    "num_samples=1\n",
    "\n",
    "height=64\n",
    "\n",
    "width=64\n",
    "\n",
    "no_of_channels=3\n",
    "\n",
    "new_feature_vector=flattened_vector.reshape(num_samples,height,width,no_of_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0215c6d-d9c6-4a6d-9583-5a8d4b3fafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64,64,3)))  \n",
    "\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19580790-e232-4262-8129-817e4c064109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\ML_PROJECTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25054f-05e5-4fbf-ac04-4aace9f69bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "df = pd.read_excel('melanoma_org_1.xlsx')\n",
    "\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "def process_batch(batch_df):\n",
    "    features = []\n",
    "    for index, row in batch_df.iterrows():\n",
    "        img_name = row['image_name']\n",
    "        status = row['status']\n",
    "        if status == 0:\n",
    "            img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign', img_name)\n",
    "        else:\n",
    "            img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\malignant', img_name)\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "        try:\n",
    "            img = load_and_preprocess_image(img_path)\n",
    "            feature_vector = model.predict(img)\n",
    "            feature_vector = feature_vector.flatten()\n",
    "            features.append([img_name, feature_vector])\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File not found: {img_path}\")\n",
    "            continue\n",
    "    return features\n",
    "\n",
    "batch_size = 200\n",
    "all_features = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[i:i+batch_size]\n",
    "    batch_features = process_batch(batch_df)\n",
    "    all_features.extend(batch_features)\n",
    "    \n",
    "    \n",
    "    intermediate_df = pd.DataFrame(batch_features, columns=['Image_name', 'Feature_vector'])\n",
    "    intermediate_df.to_pickle(f'inceptionv3_features_batch_{i//batch_size}.pkl')\n",
    "    \n",
    "    \n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48bcb7d-af31-428f-8dbe-7fcdf9eb95fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "for i in range(10):\n",
    "    filename=f\"inceptionv3_features_batch_{i}.pkl\"\n",
    "    with open(filename,'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        data_list.append(data)\n",
    "\n",
    "\n",
    "concatenated_data=np.concatenate(data_list,axis=0)\n",
    "\n",
    "with open('inceptionv3_features_concatenated.pkl','wb') as f:\n",
    "    pickle.dump(concatenated_data,f)\n",
    "\n",
    "print(\"Concatenation complete and saved to 'inceptionv3_features_concatenated.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4a2f6-21bd-4fb6-a183-0f32dbfcda0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('inceptionv3_features_concatenated.pkl','rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "for images,f_v in data:\n",
    "    print(f'image:{images},{f_v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463f21e-64cd-4118-b460-0b623230ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "df = pd.read_excel('melanoma_org_1.xlsx')\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "def process_batch(batch_df):\n",
    "    features = []\n",
    "    for index, row in batch_df.iterrows():\n",
    "        img_name = row['image_name']\n",
    "        status = row['status']\n",
    "        if status == 0:\n",
    "            img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\benign', img_name)\n",
    "        else:\n",
    "            img_path = os.path.join('C:\\\\ML_PROJECTS\\\\melanoma_cancer_dataset\\\\train\\\\malignant', img_name)\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "        try:\n",
    "            img = load_and_preprocess_image(img_path)\n",
    "            feature_vector = model.predict(img)\n",
    "            feature_vector = feature_vector.flatten()\n",
    "            features.append([img_name, feature_vector])\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File not found: {img_path}\")\n",
    "            continue\n",
    "    return features\n",
    "\n",
    "batch_size = 200\n",
    "all_features = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[i:i+batch_size]\n",
    "    batch_features = process_batch(batch_df)\n",
    "    all_features.extend(batch_features)\n",
    "    \n",
    "    \n",
    "    intermediate_df = pd.DataFrame(batch_features, columns=['Image_name', 'Feature_vector'])\n",
    "    intermediate_df.to_pickle(f'resnet50_features_batch_{i//batch_size}.pkl')\n",
    "    \n",
    "    \n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8fb1f-2291-45d2-bff6-757eae331e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_list=[]\n",
    "\n",
    "for i in range(10):\n",
    "    filename=f\"resnet50_features_batch_{i}.pkl\"\n",
    "    with open(filename,'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        data_list.append(data)\n",
    "\n",
    "\n",
    "concatenated_data=np.concatenate(data_list,axis=0)\n",
    "\n",
    "with open('resnet50_features_concatenated.pkl','wb') as f:\n",
    "    pickle.dump(concatenated_data,f)\n",
    "\n",
    "print(\"Concatenation complete and saved to 'resnet50_features_concatenated.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2807d2b-7fa3-4fd8-960b-0246cf775743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('resnet50_features_concatenated.pkl','rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "for images,f_v in data:\n",
    "    print(f'image:{images},{f_v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a5451-fb94-4ab2-b305-2717145d9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\ML_PROJECTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2c703-bd74-4cd2-88ca-d2b29cffd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "f1='vgg16_features_concatenated_test.pkl'\n",
    "f2='vgg19_features_concatenated.pkl'\n",
    "f3='resnet50_features_concatenated.pkl'\n",
    "f4='densenet_features_concatenated.pkl'\n",
    "# f5='inceptionv3_features_concatenated.pkl'\n",
    "\n",
    "with open(f4,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "for images,f_v in data:\n",
    "    print(f'{images}...{f_v.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b286d9c-4a29-470b-8134-08485c937366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "original_array=np.random.rand(100352)\n",
    "\n",
    "extended_array=np.pad(original_array,(0,115),mode='constant')\n",
    "\n",
    "num_samples = 1\n",
    "height = 183\n",
    "width = 183\n",
    "no_of_channels = 3\n",
    "reshaped_array = extended_array.reshape(num_samples, height, width, no_of_channels)\n",
    "\n",
    "print(reshaped_array.shape)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(182,182,3)))  \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02959d9d-dfb6-40a8-8c1a-b1b96be63aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "original_array=np.random.rand(131072)\n",
    "\n",
    "extended_array=np.pad(original_array,(0,1228),mode='constant')\n",
    "\n",
    "num_samples = 1\n",
    "height = 210\n",
    "width = 210\n",
    "no_of_channels = 3\n",
    "reshaped_array = extended_array.reshape(num_samples, height, width, no_of_channels)\n",
    "\n",
    "print(reshaped_array.shape)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(182,182,3)))  \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "pred_fv=model.predict(f_v)\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41486e-982d-44f3-b81a-2cd50c12a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "import numpy as np\n",
    "\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(92,92,3)))  \n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(1024, activation='relu'))\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1='vgg16_features_concatenated.pkl'\n",
    "with open(f1,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "for image,f_v in data:\n",
    "    input_shape=f_v.shape\n",
    "    # print(input_shape[0])\n",
    "    original_array=np.random.rand(input_shape[0])\n",
    "    padded_array=np.pad(original_array,(0,304),mode='constant')\n",
    "    num_samples=1\n",
    "    height=92\n",
    "    width=92\n",
    "    no_of_channels=3\n",
    "    reshaped_array = padded_array.reshape(num_samples, height, width, no_of_channels)\n",
    "    features=model1.predict(reshaped_array)\n",
    "    filename=f'vgg16_{image}_reduced_features.pkl'\n",
    "\n",
    "    with open(filename,'wb') as f:\n",
    "       pickle.dump(features,f)\n",
    "    \n",
    "    print(f'Dimension reduced and features saved for {image} successfully to {filename}!!')\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925b7d6-5896-4113-9857-3a2994ba1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "import numpy as np\n",
    "\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(92,92,3)))  \n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(1024, activation='relu'))\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1='vgg16_features_concatenated.pkl'\n",
    "with open(f1,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "for image,f_v in data:\n",
    "    input_shape=f_v.shape\n",
    "    # print(input_shape[0])\n",
    "    original_array=np.random.rand(input_shape[0])\n",
    "    padded_array=np.pad(original_array,(0,304),mode='constant')\n",
    "    num_samples=1\n",
    "    height=92\n",
    "    width=92\n",
    "    no_of_channels=3\n",
    "    reshaped_array = padded_array.reshape(num_samples, height, width, no_of_channels)\n",
    "    features=model1.predict(reshaped_array)\n",
    "    filename=f'vgg19_{image}_reduced_features.pkl'\n",
    "\n",
    "    with open(filename,'wb') as f:\n",
    "       pickle.dump(features,f)\n",
    "    \n",
    "    print(f'Dimension reduced and features saved for {image} successfully to {filename}!!')\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903b7d1-2a49-41d2-9c1a-527858293f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "count=0\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith ('vgg16_') and image.endswith('_reduced_features.pkl'):\n",
    "        count+=1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32af625-ad23-4c18-9a5f-77faa01128e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "count=0\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith ('vgg19_') and image.endswith('_reduced_features.pkl'):\n",
    "        count+=1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798865e2-eb5f-4ff5-8a52-26edb8ca0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith ('vgg19_') and image.endswith('_reduced_features.pkl'):\n",
    "        with open(image,'rb') as f:\n",
    "            feature_vector=pickle.load(f)\n",
    "            print((feature_vector.shape))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b50f59-4eb4-4ba9-8760-69223e964503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "import numpy as np\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(210,210,3)))  \n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(1024, activation='relu'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1='inceptionv3_features_concatenated.pkl'\n",
    "with open(f1,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "for image,f_v in data:\n",
    "    input_shape=f_v.shape\n",
    "    # print(input_shape[0])\n",
    "    original_array=np.random.rand(input_shape[0])\n",
    "    padded_array=np.pad(original_array,(0,1228),mode='constant')\n",
    "    num_samples=1\n",
    "    height=210\n",
    "    width=210\n",
    "    no_of_channels=3\n",
    "    reshaped_array = padded_array.reshape(num_samples, height, width, no_of_channels)\n",
    "    features=model2.predict(reshaped_array)\n",
    "    filename=f'inceptionv3_{image}_reduced_features.pkl'\n",
    "\n",
    "    with open(filename,'wb') as f:\n",
    "       pickle.dump(features,f)\n",
    "    \n",
    "    print(f'Dimension reduced and features saved for {image} successfully to {filename}!!')\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1ae65-e288-4dea-88ce-44f0839f1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "count=0\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith ('inceptionv3_') and image.endswith('_reduced_features.pkl'):\n",
    "        count+=1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba962ce3-4a9c-42db-b500-d02b1f43fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith('inceptionv3_') and image.endswith('_reduced_features.pkl'):\n",
    "        with open(image,'rb') as f:\n",
    "            feature_vector=pickle.load(f)\n",
    "            print(feature_vector.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0d525-b782-444d-917c-ed04f1642abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "import numpy as np\n",
    "\n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(182,183,3)))  \n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(1024, activation='relu'))\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1='resnet50_features_concatenated.pkl'\n",
    "with open(f1,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "for image,f_v in data:\n",
    "    input_shape=f_v.shape\n",
    "    #print(input_shape[0])\n",
    "    original_array=np.random.rand(input_shape[0])\n",
    "    padded_array=np.pad(original_array,(0,115),mode='constant')\n",
    "    num_samples=1\n",
    "    height=183\n",
    "    width=183\n",
    "    no_of_channels=3\n",
    "    reshaped_array = padded_array.reshape(num_samples, height, width, no_of_channels)\n",
    "    features=model3.predict(reshaped_array)\n",
    "    filename=f'resnet50_{image}_reduced_features.pkl'\n",
    "\n",
    "    with open(filename,'wb') as f:\n",
    "       pickle.dump(features,f)\n",
    "    \n",
    "    print(f'Dimension reduced and features saved for {image} successfully to {filename}!!')\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c7e0c-970d-4d8f-ae3a-01a745631957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "count=0\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith ('resnet50_') and image.endswith('_reduced_features.pkl'):\n",
    "        count+=1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b881e-c5b5-4c29-90a7-9ed12f1fb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith('resnet50_') and image.endswith('_reduced_features.pkl'):\n",
    "        with open(image,'rb') as f:\n",
    "            feature_vector=pickle.load(f)\n",
    "            print(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa2a08-469e-49be-a2ea-d430158a3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "os.chdir('C:\\\\ML_PROJECTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d98e2e-031f-4acf-8864-d32c1592402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "count=0\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith(f'{model}_') and image.endswith('_reduced_features.pkl'):\n",
    "        count+=1\n",
    "        i_name=image\n",
    "        if count==1:\n",
    "            break\n",
    "\n",
    "print(i_name)\n",
    "\n",
    "parts=i_name.split('_')\n",
    "\n",
    "print(parts)\n",
    "\n",
    "new_i_name=parts[1]+'_'+parts[2]\n",
    "\n",
    "print(new_i_name)\n",
    "\n",
    "f1=\"densenet_features_concatenated.pkl\"\n",
    "\n",
    "feature=[]\n",
    "\n",
    "for model in ['vgg16','vgg19','inceptionv3','resnet50']:\n",
    "    filename=f'{model}_{new_i_name}_reduced_features.pkl'\n",
    "    with open(filename,'rb') as f:\n",
    "        f_v=pickle.load(f)\n",
    "        print(f_v.shape[1])\n",
    "        feature.append(f_v)\n",
    "with open(f1,'rb') as f2:\n",
    "    data=pickle.load(f2)\n",
    "    for images,f_v_1 in data:\n",
    "        if new_i_name in images:\n",
    "            print(f'{f_v_1.shape[0]}')\n",
    "            feature.append(f_v_1)\n",
    "\n",
    "print(len(feature))\n",
    "print(feature)\n",
    "\n",
    "# feature_arr=np.array(feature)\n",
    "\n",
    "# print(feature_arr.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb334f-d4d1-48f5-b77a-d7c88dc9131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "images = os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "\n",
    "f1 = \"densenet_features_concatenated.pkl\"\n",
    "\n",
    "\n",
    "models = ['vgg16', 'vgg19', 'inceptionv3', 'resnet50']\n",
    "\n",
    "\n",
    "for image in images:\n",
    "   \n",
    "    if image.startswith('vgg16_') and image.endswith('_reduced_features.pkl'):\n",
    "        parts = image.split('_')\n",
    "        new_i_name = parts[1] + '_' + parts[2]\n",
    "\n",
    "        feature = []\n",
    "\n",
    "       \n",
    "        for model in models:\n",
    "            filename = f'{model}_{new_i_name}_reduced_features.pkl'\n",
    "            try:\n",
    "                with open(filename, 'rb') as f:\n",
    "                    f_v = pickle.load(f)\n",
    "                    print(f'Loaded {filename}: {f_v.shape[1]}')\n",
    "                    feature.append(f_v)\n",
    "            except FileNotFoundError:\n",
    "                print(f'File {filename} not found. Skipping this model.')\n",
    "\n",
    "        \n",
    "        with open(f1, 'rb') as f2:\n",
    "            data = pickle.load(f2)\n",
    "            for images, f_v_1 in data:\n",
    "                if new_i_name in images:\n",
    "                    print(f'Appending features from concatenated file: {f_v_1.shape[0]}')\n",
    "                    feature.append(f_v_1)\n",
    "\n",
    "        \n",
    "        output_filename = f'concatenated_features_{new_i_name}.pkl'\n",
    "        with open(output_filename, 'wb') as f_out:\n",
    "            pickle.dump(feature, f_out)\n",
    "            print(f'Saved concatenated features to {output_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0367b88-636f-43b3-897a-842c023a6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "count=0\n",
    "for image in images:\n",
    "  if image.startswith('concatenated_features_') and image.endswith('.pkl'):\n",
    "      count+=1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010b7fe-4c6c-43f5-aa1b-3373fc39119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_excel('melanoma_org_1.xlsx')\n",
    "\n",
    "i_name=df['image_name'].values\n",
    "label=df['status'].values\n",
    "\n",
    "images=os.listdir('C:\\\\ML_PROJECTS')\n",
    "for image in images:\n",
    "    if image.startswith('concatenated_features_') and image.endswith('.pkl'):\n",
    "        parts=image.split('_')\n",
    "        # print(parts)\n",
    "        name_parts=parts[3].split('.')\n",
    "        # print(name_parts)\n",
    "        image_name=parts[2]+'_'+name_parts[0]+'.'+name_parts[1]\n",
    "        print(image_name)\n",
    "        print('\\t')\n",
    "        with open(image,'rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            for f_v in data:\n",
    "                print(f_v)\n",
    "        if image_name in i_name:\n",
    "            index=list(i_name).index(image_name)\n",
    "            image_label=label[index]\n",
    "            print(image_label)\n",
    "           \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd362f05-ebe1-4578-bacd-58016bab72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_excel('melanoma_org_1.xlsx')\n",
    "i_name = df['image_name'].values\n",
    "label = df['status'].values\n",
    "\n",
    "\n",
    "data_to_save = []\n",
    "\n",
    "images = os.listdir('C:\\\\ML_PROJECTS')\n",
    "\n",
    "for image in images:\n",
    "    if image.startswith('concatenated_features_') and image.endswith('.pkl'):\n",
    "        parts = image.split('_')\n",
    "        name_parts = parts[3].split('.')\n",
    "        image_name = parts[2] + '_' + name_parts[0] + '.' + name_parts[1]\n",
    "        print(image_name)\n",
    "        \n",
    "        with open(os.path.join('C:\\\\ML_PROJECTS', image), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            concatenated_features = [f_v for f_v in data]\n",
    "        \n",
    "        if image_name in i_name:\n",
    "            \n",
    "            index = list(i_name).index(image_name)\n",
    "            image_label = label[index]\n",
    "            print(f'Image: {image_name}, Label: {image_label}')\n",
    "            \n",
    "           \n",
    "            data_to_save.append([image_name, image_label, concatenated_features])\n",
    "        else:\n",
    "            print(f'Image name {image_name} not found in labels')\n",
    "\n",
    "\n",
    "df_to_save = pd.DataFrame(data_to_save, columns=['image_name', 'label', 'feature_vector'])\n",
    "\n",
    "\n",
    "df_to_save.to_excel('features_with_labels.xlsx', index=False)\n",
    "\n",
    "print('Saved feature vectors and labels to features_with_labels.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43955a2-e02a-4a2c-b787-efc2574bacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d994b-0bda-4241-b781-a9365f9bd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bddef7c-f3ff-452f-95e6-06cf351a20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "df = pd.read_excel('features_with_labels.xlsx')\n",
    "\n",
    "X=df['feature_vector'].values\n",
    "y=df['label'].values\n",
    "\n",
    "print(type(X))\n",
    "\n",
    "def string_to_array(string):\n",
    "    try:\n",
    "        list_representation=eval(string)\n",
    "        return np.array(list_representation)\n",
    "    except:\n",
    "        return np.nan \n",
    "\n",
    "\n",
    "df['feature_vector']=df['feature_vector'].apply(string_to_array)\n",
    "\n",
    "X=df['feature_vector'].values\n",
    "print(type(X))\n",
    "\n",
    "X = np.vstack(df['feature_vector'].values)\n",
    "\n",
    "print(type(X))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655b560-5205-4e62-ae2a-42d6fdda84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\ML_PROJECTS')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497abf8-9b25-4272-bcaa-a27577fbf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_excel('melanoma_org_1.xlsx')\n",
    "\n",
    "df.head()\n",
    "\n",
    "status=df['status'].values\n",
    "print(status)\n",
    "\n",
    "image_name=df['image_name'].values\n",
    "\n",
    "print(image_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adddd7e-ae96-4774-a8c3-a633574ffa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\ML_PROJECTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce1970-9895-44ed-a2c1-7a0be225c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "base_directory='C:\\\\ML_PROJECTS'\n",
    "\n",
    "concatenated_feature_dir=os.path.join(base_directory,'concatenated_feature_dir')\n",
    "\n",
    "os.makedirs(concatenated_feature_dir,exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(base_directory):\n",
    "    if filename.startswith('concatenated_features_') and filename.endswith('.pkl'):\n",
    "        source_path=os.path.join(base_directory,filename)\n",
    "        target_path=os.path.join(concatenated_feature_dir,filename)\n",
    "        shutil.move(source_path,target_path)\n",
    "        print(f\"Moved {filename} to {concatenated_feature_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7542ac-604d-4693-b0f0-5ff32711567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_excel('melanoma_org_1.xlsx')\n",
    "\n",
    "\n",
    "base_directory = 'C:\\\\ML_PROJECTS'\n",
    "source_directory = os.path.join(base_directory, 'concatenated_feature_dir')\n",
    "\n",
    "\n",
    "label_0_dir = os.path.join(base_directory, 'label_0')\n",
    "label_1_dir = os.path.join(base_directory, 'label_1')\n",
    "\n",
    "\n",
    "os.makedirs(label_0_dir, exist_ok=True)\n",
    "os.makedirs(label_1_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    label = row['status']  \n",
    "    image_name = row['image_name']  \n",
    "    \n",
    "    \n",
    "    for filename in os.listdir(source_directory):\n",
    "        \n",
    "        if image_name in filename:\n",
    "            source_path = os.path.join(source_directory, filename)\n",
    "            \n",
    "            \n",
    "            if label == 0:\n",
    "                target_path = os.path.join(label_0_dir, filename)\n",
    "            elif label == 1:\n",
    "                target_path = os.path.join(label_1_dir, filename)\n",
    "            \n",
    "            \n",
    "            shutil.move(source_path, target_path)\n",
    "            print(f\"Moved {filename} to {target_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b5aec-8c69-4521-8351-02cad4457179",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\ML_PROJECTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29c06e-606f-44e5-9f59-b0f4df0a5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2  \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        print(f\"Loading image from path: {img_path}\")\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Unable to read image {filename}\")\n",
    "            \n",
    "            \n",
    "            img_resized = cv2.resize(img, (64, 64))\n",
    "            \n",
    "            \n",
    "            image_data.append(img_resized.flatten())\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "\n",
    "base_directory = 'C:\\\\ML_PROJECTS'\n",
    "label_0_dir = os.path.join(base_directory, 'label_0')\n",
    "label_1_dir = os.path.join(base_directory, 'label_1')\n",
    "\n",
    "\n",
    "load_images_from_folder(label_0_dir, 0)\n",
    "\n",
    "\n",
    "load_images_from_folder(label_1_dir, 1)\n",
    "\n",
    "\n",
    "X = np.array(image_data)\n",
    "y = np.array(labels)\n",
    "\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "\n",
    "if X.ndim == 1:\n",
    "    X = X.reshape(-1, 1)  \n",
    "if y.ndim > 1:\n",
    "    y = y.ravel()  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e0acc-dffb-4891-857f-494e9b5d355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\ML_PROJECTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7f210-97ae-4763-8bc3-ee7d17daebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_file_paths(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            print(f\"File exists: {img_path}\")\n",
    "        else:\n",
    "            print(f\"File not found: {img_path}\")\n",
    "\n",
    "\n",
    "check_file_paths(label_0_dir)\n",
    "check_file_paths(label_1_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc683a2-c402-47d5-91c0-e4e1fb02f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def verify_images(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        \n",
    "        try:\n",
    "            with open(img_path,'rb') as f:\n",
    "                file=pickle.load(f)\n",
    "                print(f\"Image verified: {img_path}\")\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            print(f\"Corrupted image or unreadable file: {img_path}, Error: {e}\")\n",
    "\n",
    "\n",
    "verify_images(label_0_dir)\n",
    "verify_images(label_1_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158c553-ef81-412f-99f4-32a58973a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_excel('features_with_labels.xlsx')\n",
    "count=0\n",
    "for idx,row in df.iterrows():\n",
    "    image_name=row['image_name']\n",
    "    label=row['label']\n",
    "    f_v=row['feature_vector']\n",
    "    f_v_cleaned = f_v.replace('dtype=float32', '').replace('array', 'np.array')\n",
    "    try:\n",
    "        f_v_array = eval(f_v_cleaned)  \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing feature vector: {e}\")\n",
    "        continue\n",
    "    count+=1\n",
    "    if count==1:\n",
    "        break\n",
    "\n",
    "\n",
    "print(type(f_v_array))\n",
    "\n",
    "\n",
    "print(f_v_array.flatten())\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d638da-3514-48df-80a4-46e61f26bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917e6ab-65f1-4e3b-8204-bff97219d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='densenet_features_batch_0.pkl'\n",
    "with open(filename,'rb') as f:\n",
    "    file=pickle.load(f)\n",
    "\n",
    "print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c7f059-cbc0-4d6c-a5e1-44403c67c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "base_directory='C:\\\\ML_PROJECTS'\n",
    "\n",
    "label_0_dir=os.path.join(base_directory,\"label_0\")\n",
    "\n",
    "print(label_0_dir)\n",
    "\n",
    "image_name=\"concatenated_features_melanoma_13.jpg.pkl\"\n",
    "\n",
    "image_dir=os.path.join(label_0_dir,image_name)\n",
    "\n",
    "print(image_dir)\n",
    "\n",
    "with open(image_dir,'rb') as f:\n",
    "    file=pickle.load(f)\n",
    "    \n",
    " \n",
    "print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5de1e-34c3-40e1-8ea3-b42f6834bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "models=['vgg16','vgg19','inceptionv3','resnet50']\n",
    "\n",
    "for model in models:\n",
    "    filename=f'{model}_melanoma_9.jpg_reduced_features.pkl'\n",
    "    with open(filename,'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556bb8f-7d5f-4795-a705-06e91f335ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "filename='vgg16_melanoma_9.jpg_reduced_features.pkl'\n",
    "with open(filename,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "f2='resnet50_melanoma_9.jpg_reduced_features.pkl'\n",
    "f3='vgg19_melanoma_9.jpg_reduced_features.pkl'\n",
    "f4='inceptionv3_melanoma_9.jpg_reduced_features.pkl'\n",
    "f5='densenet_features_concatenated.pkl'\n",
    "with open(f2,'rb') as f:\n",
    "    data1=pickle.load(f)\n",
    "\n",
    "with open(f3,'rb') as f:\n",
    "    data2=pickle.load(f)\n",
    "\n",
    "with open(f4,'rb') as f:\n",
    "    data3=pickle.load(f)\n",
    "with open(f5,'rb') as f:\n",
    "    data4=pickle.load(f)\n",
    "list=[]\n",
    "\n",
    "def get_f_v_densenet(data4):\n",
    "    for img,f_v in data4:\n",
    "        if 'melanoma_9_' in img:\n",
    "           print(img)\n",
    "    return f_v        \n",
    "i=0     \n",
    "\n",
    "f_v=get_f_v_densenet(data4)\n",
    "\n",
    "\n",
    "\n",
    "for j in range(1024):\n",
    "    x=0\n",
    "    x=(data[i][j]+data1[i][j]+data2[i][j]+data3[i][j]+f_v[j])/5\n",
    "    list.append(x)\n",
    "\n",
    "print(list)\n",
    "\n",
    "arr=np.array(list)\n",
    "\n",
    "print(arr.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcd0f6-7fd6-4044-9103-7ad2ea99395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f5='densenet_features_concatenated.pkl'\n",
    "\n",
    "with open(f5,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "def get_f_v(data):\n",
    "    for img,f_v in data:\n",
    "        if 'melanoma_9_' in img:\n",
    "            print(img)\n",
    "    return f_v\n",
    "\n",
    "f_v=get_f_v(data)\n",
    "\n",
    "for i in range(1023):\n",
    "    print(f_v[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf978982-1454-4bab-8e02-5dfe2730eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_dir='C:\\\\ML_PROJECTS'\n",
    "\n",
    "label_0_dir=os.path.join(base_dir,'label_0')\n",
    "label_1_dir=os.path.join(base_dir,'label_1')\n",
    "\n",
    "def search_label_0_dir(filename):\n",
    "    for files in os.listdir(label_0_dir):\n",
    "       if filename in files:\n",
    "           return 1\n",
    "    return 0\n",
    "\n",
    "def search_label_1_dir(filename):\n",
    "    for files in os.listdir(label_1_dir):\n",
    "       if filename in files:\n",
    "           return 1\n",
    "    return 0\n",
    "\n",
    "df=pd.read_excel('melanoma_org_1.xlsx')\n",
    "label=[]\n",
    "for idx,row in df.iterrows():\n",
    "    image_name=row['image_name']\n",
    "    filename=f'concatenated_features_{image_name}.pkl'\n",
    "    x=search_label_0_dir(filename)\n",
    "    y=search_label_1_dir(filename)\n",
    "    if x:\n",
    "        label.append(0)\n",
    "    if y:\n",
    "        label.append(1)\n",
    "\n",
    "print(label)\n",
    "\n",
    "arr=np.array(label)\n",
    "\n",
    "print(arr.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fbfb2-4c65-4618-a9c6-78f58384bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def get_feature_vector(image_name):\n",
    "    l=[]\n",
    "    x=0\n",
    "    i=0\n",
    "    f1=f'vgg16_{image_name}_reduced_features.pkl'\n",
    "    with open(f1,'rb') as f:\n",
    "        data1=pickle.load(f)\n",
    "    f2=f'vgg19_{image_name}_reduced_features.pkl'\n",
    "    with open(f2,'rb') as f:\n",
    "        data2=pickle.load(f)\n",
    "    f3=f'resnet50_{image_name}_reduced_features.pkl'\n",
    "    with open(f3,'rb') as f:\n",
    "        data3=pickle.load(f)\n",
    "    f4=f'inceptionv3_{image_name}_reduced_features.pkl'\n",
    "    with open(f4,'rb') as f:\n",
    "        data4=pickle.load(f)\n",
    "    f5=f'densenet_features_concatenated.pkl'\n",
    "    with open(f5,'rb') as f:\n",
    "        data5=pickle.load(f)\n",
    "    f_v=get_f_v_densenet(data5,image_name)\n",
    "    for j in range(1024):\n",
    "        x=data1[i][j]+data2[i][j]+data3[i][j]+data4[i][j]+f_v[j]\n",
    "        l.append(x)\n",
    "\n",
    "    print(l)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "def get_f_v_densenet(data5,image_name):\n",
    "    for img,f_v in data5:\n",
    "        if image_name in img:\n",
    "           return f_v       \n",
    "\n",
    "base_dir='C:\\\\ML_PROJECTS'\n",
    "\n",
    "label_0_dir=os.path.join(base_dir,'label_0')\n",
    "label_1_dir=os.path.join(base_dir,'label_1')\n",
    "\n",
    "def search_label_0_dir(filename):\n",
    "    for files in os.listdir(label_0_dir):\n",
    "       if filename in files:\n",
    "           return 1\n",
    "    return 0\n",
    "\n",
    "def search_label_1_dir(filename):\n",
    "    for files in os.listdir(label_1_dir):\n",
    "       if filename in files:\n",
    "           return 1\n",
    "    return 0\n",
    "\n",
    "df=pd.read_excel('melanoma_org_1.xlsx')\n",
    "label=[]\n",
    "for idx,row in df.iterrows():\n",
    "    image_name=row['image_name']\n",
    "    print(image_name)\n",
    "    filename=f'concatenated_features_{image_name}.pkl'\n",
    "    get_feature_vector(image_name)\n",
    "    x=search_label_0_dir(filename)\n",
    "    y=search_label_1_dir(filename)\n",
    "    print('label:\\t')\n",
    "    if x:\n",
    "        label.append(0)\n",
    "        print(x)\n",
    "    if y:\n",
    "        label.append(1)\n",
    "        print(y)\n",
    "\n",
    "print(label)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f1c86-061f-4c0d-aa37-1c6506e66c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
